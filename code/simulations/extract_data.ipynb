{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from parcels import FieldSet, ParticleSet, Variable, JITParticle, AdvectionRK4, plotTrajectoriesFile\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import timedelta\n",
    "from operator import attrgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify target populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\n",
    "    'Rovinj',\n",
    "    'Valsaline',\n",
    "    'Sarkodana',\n",
    "    'Cres',\n",
    "    'Krk_neu',\n",
    "    'Krk_Baska',\n",
    "    'Klenovica',\n",
    "    'Rab',\n",
    "    'HafenPag_neu',\n",
    "    'Pag',\n",
    "    'PagerBucht',\n",
    "    'Pag_Holger',\n",
    "    'DugiOtok',\n",
    "    'Ugljan_neu',\n",
    "    'Pasman',\n",
    "    'SibenikDolac_neu',\n",
    "    'Kornaten_Sued',\n",
    "    'TrogirCiovoWest',\n",
    "    'BracSupetarSutivan',\n",
    "    'BracPovlja',\n",
    "    'CampAloaBol',\n",
    "    'HvarBucht4',\n",
    "    'HvarMlaska',\n",
    "    'HvarBogomoje',\n",
    "    'Mljet',\n",
    "    'Molunat_neu'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will just read the nc files produced by parcels for each location and write out the final coordinates for each of the particles to a tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "#drift duration in days\n",
    "drift = 20\n",
    "\n",
    "dictionary = {}\n",
    "for loc in target:\n",
    "    dictionary[loc] = {'time':[], 'lat':[], 'lon':[]}\n",
    "    \n",
    "#    fh = open(loc+'.data.tsv')\n",
    "\n",
    "for year in range(2004,2019):\n",
    "    print (year)\n",
    "    for nc in sorted(glob.glob(str(year) + \"/release-*.nc\")):\n",
    "        print (nc)\n",
    "        data = Dataset(nc, 'r')\n",
    "        #the number of particles\n",
    "        num_locations = int(data.dimensions['traj'].size)\n",
    "        num_observations = int(data.dimensions['obs'].size)\n",
    "        for loc_index in range(num_locations):\n",
    "\n",
    "            # extract release timepoint from filename\n",
    "            release = np.datetime64(\"T\".join([\"-\".join(nc.split('T')[0].split(\"-\")[1:]), \":\".join(nc.replace(\".nc\",\"\").split('T')[1].split(\"-\"))]))\n",
    "            # caculate last timepoint\n",
    "            last = release + np.timedelta64(drift, 'D')\n",
    "            dictionary[target[loc_index]]['time'].append(last)\n",
    "            dictionary[target[loc_index]]['lat'].append(data.variables['lat'][loc_index][-1])\n",
    "            dictionary[target[loc_index]]['lon'].append(data.variables['lon'][loc_index][-1])\n",
    "\n",
    "for loc in dictionary:\n",
    "    print (loc)\n",
    "    fh = open('data/'+loc+'.data.tsv', 'w')\n",
    "    for i in range(len(dictionary[loc]['time'])):\n",
    "        fh.write(\"%s\\t%s\\t%s\\n\" %(dictionary[loc]['time'][i], dictionary[loc]['lat'][i], dictionary[loc]['lon'][i]))\n",
    "    fh.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
