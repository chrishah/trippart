{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download relevant data from the AREG model as provided by the Adriatic forecasting system ([AFS](http://oceanlab.cmcc.it/afs/)). Our simulations only cover the period of February to September so we will only download data for these months (01-09) for the years 2004-2018.\n",
    "\n",
    "Next field will download all files - will take a while - be patient.",
    "\n\n",
    "__Disclaimer:__ Since the beginning of 2020 the AFS is not operational any more and has stopped maintaining the servers which hosted the AREG data originally, so the code for downloading the data below does not work any more. However, the raw data used for the simulations below can still be obtained from the CMCC (download link will be provide on request. contact: operation_ocean-lab@cmcc.it). Alternatively, please contact Christoph Hahn (christoph.hahn@uni-graz.at) if would like to reproduce the analalyses (as described in Sefc et al. 2020). We have all raw data backed up and are happy to provide it on request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#this is where the AFS has currently deposited their data\n",
    "baseurl='http://tds.tessa.cmcc.it/thredds/fileServer/AFS/simulation/day'\n",
    "startyear=2004\n",
    "endyear=2018\n",
    "startmonth=01\n",
    "endmonth=09\n",
    "\n",
    "for year in $(seq $startyear $endyear)\n",
    "do\n",
    "    echo -e \"$year\"\n",
    "    mkdir $year\n",
    "    \n",
    "    #the following is just a complicated way to download only files for the range of months specified\n",
    "    #The first loop formats the month number with a leading zero if necessary\n",
    "    #the second loop downloads the list of files per year and greps only the ones for the current month\n",
    "    #the third one does the downloading\n",
    "    for l in $(for j in $(for i in $(seq $startmonth $endmonth)\n",
    "    do\n",
    "        echo $i\n",
    "    done | perl -ne 'chomp; print sprintf(\"%02d\",$_).\"\\n\"')\n",
    "    do\n",
    "        wget -qO- http://tds.tessa.cmcc.it/thredds/catalog/AFS/simulation/day/$year/catalog.html | grep \"simu.nc.gz\" | grep -P \"$j.._areg\"\n",
    "    done | sed 's/ /|/g')\n",
    "    do\n",
    "        #this part does the actual downloading\n",
    "        filename=$(echo -e \"$l\" | cut -d \"'\" -f 2 | perl -ne 'chomp; @a=split(\"/\"); print \"$a[-1]\\n\"')\n",
    "        echo \"downloading $baseurl/$year/$filename -> $year/$filename\"\n",
    "        wget -qO $year/$filename $baseurl/$year/$filename\n",
    "    done\n",
    "\n",
    "#    #decompress files\n",
    "#    for file in $(find ./$year/ -name \"*.gz\")\n",
    "#    do\n",
    "#        gunzip -v $file\n",
    "#    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from parcels import FieldSet, ParticleSet, Variable, JITParticle, AdvectionRK4, plotTrajectoriesFile\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import timedelta\n",
    "from operator import attrgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify target populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\n",
    "    'Rovinj',\n",
    "    'Valsaline',\n",
    "    'Sarkodana',\n",
    "    'Cres',\n",
    "    'Krk_neu',\n",
    "    'Krk_Baska',\n",
    "    'Klenovica',\n",
    "    'Rab',\n",
    "    'HafenPag_neu',\n",
    "    'Pag',\n",
    "    'PagerBucht',\n",
    "    'Pag_Holger',\n",
    "    'DugiOtok',\n",
    "    'Ugljan_neu',\n",
    "    'Pasman',\n",
    "    'SibenikDolac_neu',\n",
    "    'Kornaten_Sued',\n",
    "    'TrogirCiovoWest',\n",
    "    'BracSupetarSutivan',\n",
    "    'BracPovlja',\n",
    "    'CampAloaBol',\n",
    "    'HvarBucht4',\n",
    "    'HvarMlaska',\n",
    "    'HvarBogomoje',\n",
    "    'Mljet',\n",
    "    'Molunat_neu'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in lat lon coordinates from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open('coordinates_MAX.csv')\n",
    "\n",
    "fh.readline()\n",
    "\n",
    "populations = []\n",
    "region = []\n",
    "start_lon = []\n",
    "start_lat = []\n",
    "\n",
    "for line in fh.readlines():\n",
    "    line = line.strip()\n",
    "#    print (line)\n",
    "    if line.split(\",\")[0] in target:\n",
    "        populations.append(line.split(\",\")[1])\n",
    "        region.append(line.split(\",\")[2])\n",
    "        start_lon.append(line.split(\",\")[-2])\n",
    "        start_lat.append(line.split(\",\")[-1])\n",
    "    \n",
    "#print (populations, region, start_lon, start_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the simulations year by year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First decompress all files and specify some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2004\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2004\n",
    "#specify start/end date for simulation\n",
    "start = '2004-02-01'\n",
    "end = '2004-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define fieldset for parcels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check time data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define start time/date and end time/date\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the particles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset[0].show(field=fieldset.U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"./2004/release-2004-02-01T00-00-00.000000000.nc\"\n",
    "plotTrajectoriesFile(file,\n",
    "                     mode='2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrajectoriesFile(file,\n",
    "                     tracerfile='./2004/20040217_areg2c_simu.nc',\n",
    "                     tracerlon='lon_u',\n",
    "                     tracerlat='lat_v',\n",
    "                     tracerfield='depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2004\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2005\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all from above in one cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2005\n",
    "#specify start/end date for simulation\n",
    "start = '2005-02-01'\n",
    "end = '2005-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2005\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2006\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2006\n",
    "#specify start/end date for simulation\n",
    "start = '2006-02-01'\n",
    "end = '2006-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2006\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2007\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2007\n",
    "#specify start/end date for simulation\n",
    "start = '2007-02-01'\n",
    "end = '2007-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2007\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2008\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2008\n",
    "#specify start/end date for simulation\n",
    "start = '2008-02-01'\n",
    "end = '2008-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2008\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2009\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2009\n",
    "#specify start/end date for simulation\n",
    "start = '2009-02-01'\n",
    "end = '2009-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2009\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2010\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2010\n",
    "#specify start/end date for simulation\n",
    "start = '2010-02-01'\n",
    "end = '2010-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2010\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2011\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2011\n",
    "#specify start/end date for simulation\n",
    "start = '2011-02-01'\n",
    "end = '2011-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2011\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2012\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2012\n",
    "#specify start/end date for simulation\n",
    "start = '2012-02-01'\n",
    "end = '2012-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2012\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2013\n",
    "\n",
    "#in 2013 there is a switch from areg2d to areg2c and there is one week for which two versions are available\n",
    "#the below code just decompresses the data for weeks that are unique and if duplicated decompresses only \n",
    "#one of the files. Otherwise parcels is not going to accept the fieldset.\n",
    "\n",
    "#decompress only weeks for which only a single file is available\n",
    "for valid in $(ls -1 ./$year/*.gz | cut -d \"_\" -f 1 |sort -n | uniq -c | grep \"^.*1 \" | perl -ne 'chomp; @a=split(\" \"); print \"$a[-1]\\n\"')\n",
    "do\n",
    "    gunzip -v $valid*\n",
    "done\n",
    "\n",
    "#for dates for which more than one file are available decompress only one\n",
    "for duplicate in $(ls -1 ./$year/*.gz | cut -d \"_\" -f 1 |sort -n | uniq -c | grep -v \"^.*1 \" | perl -ne 'chomp; @a=split(\" \"); print \"$a[-1]\\n\"')\n",
    "do\n",
    "    gunzip -v $(ls -1 $duplicate* | sort -n | head -n 1)\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2013\n",
    "#specify start/end date for simulation\n",
    "start = '2013-02-01'\n",
    "end = '2013-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2013\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2014\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2014\n",
    "#specify start/end date for simulation\n",
    "start = '2014-02-01'\n",
    "end = '2014-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2014\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2015\n",
    "\n",
    "#in year 2015 there was a switch from 0.25 degrees resolution to 0.125 degrees resolution, so for some weeks \n",
    "#there are two files. we'll only decompress the one with 0.125 degrees resolution otherwise parcels will not\n",
    "#accept the fieldset.\n",
    "\n",
    "#decompress only weeks for which only a single file is available\n",
    "for valid in $(ls -1 ./$year/*.gz | cut -d \"_\" -f 1 |sort -n | uniq -c | grep \"^.*1 \" | perl -ne 'chomp; @a=split(\" \"); print \"$a[-1]\\n\"')\n",
    "do\n",
    "    gunzip -v $valid*\n",
    "done\n",
    "\n",
    "#for dates for which more than one file are available choose only one\n",
    "for duplicate in $(ls -1 ./$year/*.gz | cut -d \"_\" -f 1 |sort -n | uniq -c | grep -v \"^.*1 \" | perl -ne 'chomp; @a=split(\" \"); print \"$a[-1]\\n\"')\n",
    "do\n",
    "    gunzip -v $(ls -1 $duplicate* | sort -n | head -n 1)\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2015\n",
    "#specify start/end date for simulation\n",
    "start = '2015-02-01'\n",
    "end = '2015-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2015\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2016\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2016\n",
    "#specify start/end date for simulation\n",
    "start = '2016-02-01'\n",
    "end = '2016-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2016\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2017\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2017\n",
    "#specify start/end date for simulation\n",
    "start = '2017-02-01'\n",
    "end = '2017-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2017\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2018\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "#specify start/end date for simulation\n",
    "start = '2018-02-01'\n",
    "end = '2018-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2018\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
