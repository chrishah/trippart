{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download relevant data from the AREG model as provided by the Adriatic forecasting system ([AFS](http://oceanlab.cmcc.it/afs/)). Our simulations only cover the period of February to September so we will only download data for these months (01-09) for the years 2004-2018.\n",
    "\n",
    "Next field will download all files - will take a while - be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#this is where the AFS has currently deposited their data\n",
    "baseurl='http://tds.tessa.cmcc.it/thredds/fileServer/AFS/simulation/day'\n",
    "startyear=2004\n",
    "endyear=2018\n",
    "startmonth=01\n",
    "endmonth=09\n",
    "\n",
    "for year in $(seq $startyear $endyear)\n",
    "do\n",
    "    echo -e \"$year\"\n",
    "    mkdir $year\n",
    "    \n",
    "    #the following is just a complicated way to download only files for the range of months specified\n",
    "    #The first loop formats the month number with a leading zero if necessary\n",
    "    #the second loop downloads the list of files per year and greps only the ones for the current month\n",
    "    #the third one does the downloading\n",
    "    for l in $(for j in $(for i in $(seq $startmonth $endmonth)\n",
    "    do\n",
    "        echo $i\n",
    "    done | perl -ne 'chomp; print sprintf(\"%02d\",$_).\"\\n\"')\n",
    "    do\n",
    "        wget -qO- http://tds.tessa.cmcc.it/thredds/catalog/AFS/simulation/day/$year/catalog.html | grep \"simu.nc.gz\" | grep -P \"$j.._areg\"\n",
    "    done | sed 's/ /|/g')\n",
    "    do\n",
    "        #this part does the actual downloading\n",
    "        filename=$(echo -e \"$l\" | cut -d \"'\" -f 2 | perl -ne 'chomp; @a=split(\"/\"); print \"$a[-1]\\n\"')\n",
    "        echo \"downloading $baseurl/$year/$filename -> $year/$filename\"\n",
    "        wget -qO $year/$filename $baseurl/$year/$filename\n",
    "    done\n",
    "\n",
    "#    #decompress files\n",
    "#    for file in $(find ./$year/ -name \"*.gz\")\n",
    "#    do\n",
    "#        gunzip -v $file\n",
    "#    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from parcels import FieldSet, ParticleSet, Variable, JITParticle, AdvectionRK4, plotTrajectoriesFile\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import timedelta\n",
    "from operator import attrgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify target populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\n",
    "    'Rovinj',\n",
    "    'Valsaline',\n",
    "    'Sarkodana',\n",
    "    'Cres',\n",
    "    'Krk_neu',\n",
    "    'Krk_Baska',\n",
    "    'Klenovica',\n",
    "    'Rab',\n",
    "    'HafenPag_neu',\n",
    "    'Pag',\n",
    "    'PagerBucht',\n",
    "    'Pag_Holger',\n",
    "    'DugiOtok',\n",
    "    'Ugljan_neu',\n",
    "    'Pasman',\n",
    "    'SibenikDolac_neu',\n",
    "    'Kornaten_Sued',\n",
    "    'TrogirCiovoWest',\n",
    "    'BracSupetarSutivan',\n",
    "    'BracPovlja',\n",
    "    'CampAloaBol',\n",
    "    'HvarBucht4',\n",
    "    'HvarMlaska',\n",
    "    'HvarBogomoje',\n",
    "    'Mljet',\n",
    "    'Molunat_neu'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in lat lon coordinates from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open('coordinates_MAX.csv')\n",
    "\n",
    "fh.readline()\n",
    "\n",
    "populations = []\n",
    "region = []\n",
    "start_lon = []\n",
    "start_lat = []\n",
    "\n",
    "for line in fh.readlines():\n",
    "    line = line.strip()\n",
    "#    print (line)\n",
    "    if line.split(\",\")[0] in target:\n",
    "        populations.append(line.split(\",\")[0])\n",
    "        region.append(line.split(\",\")[1])\n",
    "        start_lon.append(line.split(\",\")[-2])\n",
    "        start_lat.append(line.split(\",\")[-1])\n",
    "    \n",
    "#print (populations, region, start_lon, start_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the simulations year by year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First decompress all files and specify some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2004\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2004\n",
    "#specify start/end date for simulation\n",
    "start = '2004-02-01'\n",
    "end = '2004-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define fieldset for parcels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check time data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define start time/date and end time/date\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the particles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset[0].show(field=fieldset.U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"./2004/release-2004-02-01T00-00-00.000000000.nc\"\n",
    "plotTrajectoriesFile(file,\n",
    "                     mode='2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrajectoriesFile(file,\n",
    "                     tracerfile='./2004/20040217_areg2c_simu.nc',\n",
    "                     tracerlon='lon_u',\n",
    "                     tracerlat='lat_v',\n",
    "                     tracerfield='depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2004\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2005\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all from above in one cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2005\n",
    "#specify start/end date for simulation\n",
    "start = '2005-02-01'\n",
    "end = '2005-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2005\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2006\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2006\n",
    "#specify start/end date for simulation\n",
    "start = '2006-02-01'\n",
    "end = '2006-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2006\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2007\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2007\n",
    "#specify start/end date for simulation\n",
    "start = '2007-02-01'\n",
    "end = '2007-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2007\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2008\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2008\n",
    "#specify start/end date for simulation\n",
    "start = '2008-02-01'\n",
    "end = '2008-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2008\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2009\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2009\n",
    "#specify start/end date for simulation\n",
    "start = '2009-02-01'\n",
    "end = '2009-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2009\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2010\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2010\n",
    "#specify start/end date for simulation\n",
    "start = '2010-02-01'\n",
    "end = '2010-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2010\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2011\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2011\n",
    "#specify start/end date for simulation\n",
    "start = '2011-02-01'\n",
    "end = '2011-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2011\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2012\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2012\n",
    "#specify start/end date for simulation\n",
    "start = '2012-02-01'\n",
    "end = '2012-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2012\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2013\n",
    "\n",
    "#in 2013 there is a switch from areg2d to areg2c and there is one week for which two versions are available\n",
    "#the below code just decompresses the data for weeks that are unique and if duplicated decompresses only \n",
    "#one of the files. Otherwise parcels is not going to accept the fieldset.\n",
    "\n",
    "#decompress only weeks for which only a single file is available\n",
    "for valid in $(ls -1 ./$year/*.gz | cut -d \"_\" -f 1 |sort -n | uniq -c | grep \"^.*1 \" | perl -ne 'chomp; @a=split(\" \"); print \"$a[-1]\\n\"')\n",
    "do\n",
    "    gunzip -v $valid*\n",
    "done\n",
    "\n",
    "#for dates for which more than one file are available decompress only one\n",
    "for duplicate in $(ls -1 ./$year/*.gz | cut -d \"_\" -f 1 |sort -n | uniq -c | grep -v \"^.*1 \" | perl -ne 'chomp; @a=split(\" \"); print \"$a[-1]\\n\"')\n",
    "do\n",
    "    gunzip -v $(ls -1 $duplicate* | sort -n | head -n 1)\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2013\n",
    "#specify start/end date for simulation\n",
    "start = '2013-02-01'\n",
    "end = '2013-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2013\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2014\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2014\n",
    "#specify start/end date for simulation\n",
    "start = '2014-02-01'\n",
    "end = '2014-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2014\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2015\n",
    "\n",
    "#in year 2015 there was a switch from 0.25 degrees resolution to 0.125 degrees resolution, so for some weeks \n",
    "#there are two files. we'll only decompress the one with 0.125 degrees resolution otherwise parcels will not\n",
    "#accept the fieldset.\n",
    "\n",
    "#decompress only weeks for which only a single file is available\n",
    "for valid in $(ls -1 ./$year/*.gz | cut -d \"_\" -f 1 |sort -n | uniq -c | grep \"^.*1 \" | perl -ne 'chomp; @a=split(\" \"); print \"$a[-1]\\n\"')\n",
    "do\n",
    "    gunzip -v $valid*\n",
    "done\n",
    "\n",
    "#for dates for which more than one file are available choose only one\n",
    "for duplicate in $(ls -1 ./$year/*.gz | cut -d \"_\" -f 1 |sort -n | uniq -c | grep -v \"^.*1 \" | perl -ne 'chomp; @a=split(\" \"); print \"$a[-1]\\n\"')\n",
    "do\n",
    "    gunzip -v $(ls -1 $duplicate* | sort -n | head -n 1)\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2015\n",
    "#specify start/end date for simulation\n",
    "start = '2015-02-01'\n",
    "end = '2015-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2015\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2016\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2016\n",
    "#specify start/end date for simulation\n",
    "start = '2016-02-01'\n",
    "end = '2016-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2016\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2017\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2017\n",
    "#specify start/end date for simulation\n",
    "start = '2017-02-01'\n",
    "end = '2017-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2017\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2018\n",
    "#decompress files\n",
    "for file in $(find ./$year/ -name \"*.gz\")\n",
    "do\n",
    "    gunzip -v $file\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "#specify start/end date for simulation\n",
    "start = '2018-02-01'\n",
    "end = '2018-09-30'\n",
    "drift = 20 #drift time in days\n",
    "#set stepsize for release in hours\n",
    "step = 12\n",
    "\n",
    "##############################################\n",
    "filenames = {'U': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\",\n",
    "             'V': \"./\"+str(year)+\"/\"+str(year)+\"*.nc\"}\n",
    "\n",
    "variables = {'U': 'U',\n",
    "             'V': 'V'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "\n",
    "#################\n",
    "\n",
    "start = np.datetime64(start+'T00:00:00.000000000')\n",
    "end = np.datetime64(end+'T23:59:59')\n",
    "\n",
    "#this is the first timepoint for which we have data in the field\n",
    "first=np.datetime64(str(fieldset.U.grid.time_origin))\n",
    "print (\"First timepoint with data: \", first)\n",
    "\n",
    "#this is the last timepoint for which we have data in the fieldset\n",
    "last=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "print (\"Last timepoint with data: \", last)\n",
    "\n",
    "if (start >= first):\n",
    "    print (\"Start time is ok: \", start)\n",
    "else:\n",
    "    print (\"Invalid start date\")\n",
    "\n",
    "if (end <= last):\n",
    "    print (\"End time is ok: \", end)\n",
    "else:\n",
    "    print (\"Invalid end date\")\n",
    "\n",
    "#if the simulation needs to run for 20 days then the last day we can start it is:\n",
    "#lastdata=np.datetime64(str(fieldset.U.grid.time_origin)) + np.timedelta64(int(fieldset.U.grid.time_full[-1]),'s')\n",
    "laststart=end - np.timedelta64(drift, 'D')\n",
    "print (\"\\nLast start\", laststart)\n",
    "\n",
    "#find the delta time from first data to desired starttime\n",
    "releasesecond = np.timedelta64(start - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "\n",
    "#at which timepoint in seconds after the origin could we start the last simulation\n",
    "laststartinseconds = np.timedelta64(laststart - np.datetime64(str(fieldset.U.grid.time_origin)), 's') / np.timedelta64(1,'s')\n",
    "#print (releasesecond, laststartinseconds)\n",
    "\n",
    "##########################\n",
    "\n",
    "### set some variables (don't change)\n",
    "meta = {}\n",
    "index = 0\n",
    "releasesecond = int(releasesecond)\n",
    "step = np.timedelta64(int(step), 'h')\n",
    "pset = {}\n",
    "\n",
    "while np.timedelta64(int(releasesecond), 's') <= np.timedelta64(int(laststartinseconds), 's'):\n",
    "    meta[index] = {'seconds-post-origin': releasesecond, 'datetime': first + np.timedelta64(releasesecond, 's')}\n",
    "    print (\"release particle\", index, \n",
    "           first + np.timedelta64(releasesecond, 's'), \n",
    "           \"(\", np.timedelta64(int(releasesecond), 's'), \"post origin)\")\n",
    "    pset[index] = ParticleSet.from_list(fieldset=fieldset, pclass=JITParticle,\n",
    "                             lon=start_lon, lat=start_lat,\n",
    "                             time=releasesecond)\n",
    "    \n",
    "    index+=1\n",
    "    releasesecond = int(releasesecond + (step / np.timedelta64(1, 's')))\n",
    "    \n",
    "################################\n",
    "\n",
    "#print (pset)\n",
    "\n",
    "for i in pset.keys():\n",
    "    print (\"particle\", i, \" /\", len(pset.keys()) - 1, \"- released:\", \n",
    "           first + np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \n",
    "           \"(\", np.timedelta64(int(meta[i]['seconds-post-origin']), 's'), \"post origin)\")\n",
    "    pset[i].execute(AdvectionRK4,\n",
    "             runtime=timedelta(days=drift),\n",
    "             dt=timedelta(minutes=5),\n",
    "             output_file=pset[i].ParticleFile(name=\"./\"+str(year)+\"/release-\"+str(meta[i]['datetime']).replace(':', '-')+\".nc\", \n",
    "                                           outputdt=timedelta(hours=6)))\n",
    "    \n",
    "###############################\n",
    "\n",
    "del(pset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "year=2018\n",
    "#compress files\n",
    "for file in $(find ./$year/ -name *.nc | grep -v \"release\")\n",
    "do\n",
    "    gzip -v $file\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
